{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "toc": {
      "nav_menu": {
        "height": "263px",
        "width": "352px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "_RvUjMTHzfzZ",
        "colab_type": "text"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Process-Data\" data-toc-modified-id=\"Process-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Process Data</a></span></li><li><span><a href=\"#Pre-Process-Data-For-Deep-Learning\" data-toc-modified-id=\"Pre-Process-Data-For-Deep-Learning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pre-Process Data For Deep Learning</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Look-at-one-example-of-processed-issue-bodies\" data-toc-modified-id=\"Look-at-one-example-of-processed-issue-bodies-2.0.0.1\"><span class=\"toc-item-num\">2.0.0.1&nbsp;&nbsp;</span>Look at one example of processed issue bodies</a></span></li><li><span><a href=\"#Look-at-one-example-of-processed-issue-titles\" data-toc-modified-id=\"Look-at-one-example-of-processed-issue-titles-2.0.0.2\"><span class=\"toc-item-num\">2.0.0.2&nbsp;&nbsp;</span>Look at one example of processed issue titles</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Define-Model-Architecture\" data-toc-modified-id=\"Define-Model-Architecture-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Define Model Architecture</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Load-the-data-from-disk-into-variables\" data-toc-modified-id=\"Load-the-data-from-disk-into-variables-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Load the data from disk into variables</a></span></li><li><span><a href=\"#Define-Model-Architecture\" data-toc-modified-id=\"Define-Model-Architecture-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Define Model Architecture</a></span></li></ul></li></ul></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train Model</a></span></li><li><span><a href=\"#See-Results-On-Holdout-Set\" data-toc-modified-id=\"See-Results-On-Holdout-Set-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>See Results On Holdout Set</a></span></li><li><span><a href=\"#Feature-Extraction-Demo\" data-toc-modified-id=\"Feature-Extraction-Demo-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Feature Extraction Demo</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Example-1:-Issues-Installing-Python-Packages\" data-toc-modified-id=\"Example-1:-Issues-Installing-Python-Packages-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Example 1: Issues Installing Python Packages</a></span></li><li><span><a href=\"#Example-2:--Issues-asking-for-feature-improvements\" data-toc-modified-id=\"Example-2:--Issues-asking-for-feature-improvements-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Example 2:  Issues asking for feature improvements</a></span></li></ul></li></ul></li></ul></div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKP0Dvpazfzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "6959b285-a38f-43b9-9fb7-e0cfd67a37ba"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Detect hardware\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError: # If TPU not found\n",
        "  tpu = None\n",
        "# Select appropriate distribution strategy\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # Default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU instead')\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.30.40.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.30.40.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.30.40.226:8470']\n",
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyuMSLWZ08Rf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "45c0d87f-44f2-4bbc-c6a2-906754946e7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'seq2seq-model/'\n",
        "import sys\n",
        "sys.path.append(base_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvYAFKU-8wS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "928a5815-2db2-47e9-abb9-c80a99c7abfb"
      },
      "source": [
        "!pip install astor\n",
        "!pip install wget\n",
        "!pip install nmslib\n",
        "!pip install pathos\n",
        "!pip install pandas\n",
        "!pip install more_itertools\n",
        "!pip install spacy\n",
        "!python -m spacy download en\n",
        "!pip install ktext\n",
        "!pip install annoy\n",
        "!pip install fastai\n",
        "!pip install torch\n",
        "!pip install torchtext\n",
        "!pip install torchvision\n",
        "import tqdm\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=c7b9ceaa026870203c185f4b162d1b182240228709d64b948b11a1db66d2430c\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting nmslib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/fd/7d7428d29f12be5d1cc6d586d425b795cc9c596ae669593fd4f388602010/nmslib-2.0.6-cp36-cp36m-manylinux2010_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0MB 303kB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from nmslib) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from nmslib) (1.18.5)\n",
            "Collecting pybind11>=2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/e3/d576f6f02bc75bacbc3d42494e8f1d063c95617d86648dba243c2cb3963e/pybind11-2.5.0-py2.py3-none-any.whl (296kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 43.2MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11, nmslib\n",
            "Successfully installed nmslib-2.0.6 pybind11-2.5.0\n",
            "Collecting pathos\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/ea/b2cf3a6561fc5deb64de8ae0af5e3e4e2db03ca588cb7415efce4a8de26e/pathos-0.2.6.zip (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 3.4MB/s \n",
            "\u001b[?25hCollecting ppft>=1.6.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/fb/fa21f6e9aedc4823448473ed96e8eab64af1cb248c18165f045a90e1c6b4/ppft-1.6.6.2.zip (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 11.0MB/s \n",
            "\u001b[?25hCollecting dill>=0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/96/518a8ea959a734b70d2e95fef98bcbfdc7adad1c1e5f5dd9148c835205a5/dill-0.3.2.zip (177kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 10.4MB/s \n",
            "\u001b[?25hCollecting pox>=0.2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/0c/ec447fb0ed88bc1c09bf0dadf00e40ea05fda17e841d15bb351a52d9e192/pox-0.2.8.zip (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 10.8MB/s \n",
            "\u001b[?25hCollecting multiprocess>=0.70.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/4e/4591c45b85fbcbcc3de9554e20e079e0006c4332e0a780ed0883f2b07965/multiprocess-0.70.10.zip (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.6/dist-packages (from ppft>=1.6.6.2->pathos) (1.12.0)\n",
            "Building wheels for collected packages: pathos, ppft, dill, pox, multiprocess\n",
            "  Building wheel for pathos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathos: filename=pathos-0.2.6-cp36-none-any.whl size=77673 sha256=8944ae0aaa4ea00e57493a36f8bb7076a95110a8369c60978495a414674a02bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/e8/c8/04cdd0c4bc6fbce35f642fc004244228916daae74bb0f482da\n",
            "  Building wheel for ppft (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ppft: filename=ppft-1.6.6.2-cp36-none-any.whl size=64743 sha256=60a61f853fce6e8a1b5cf8dfca2b51dd6f907265dc9186caec6e91601ef997e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/d2/2d/0ee21ede61786bb13247dbc69079373fd500c2bb0481913084\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.2-cp36-none-any.whl size=78913 sha256=8336c043feed01747634a09d01ed2186376199aaef9d160ce9a48e8ecba7dca0\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/4b/a2/34ccdcc2f158742cfe9650675560dea85f78c3f4628f7daad0\n",
            "  Building wheel for pox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pox: filename=pox-0.2.8-cp36-none-any.whl size=28290 sha256=6638fcd3b34dcebec8c20730800fe6f13ba82fdb0c5e79c27c21bd2bfad2f50b\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/ed/ce/a93103746b327e18bffaeb99ba0d57a88b392f31d719cea700\n",
            "  Building wheel for multiprocess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multiprocess: filename=multiprocess-0.70.10-cp36-none-any.whl size=100505 sha256=a5526d8b26aed16cda4a4db6730f4478ab86f34f7b74f34ee1c591c58ccd0a6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/97/16/5d5fc187439a97f583ff4bdafc1ae4490e1d75dd350f2c0dfa\n",
            "Successfully built pathos ppft dill pox multiprocess\n",
            "Installing collected packages: ppft, dill, pox, multiprocess, pathos\n",
            "  Found existing installation: dill 0.3.1.1\n",
            "    Uninstalling dill-0.3.1.1:\n",
            "      Successfully uninstalled dill-0.3.1.1\n",
            "  Found existing installation: multiprocess 0.70.9\n",
            "    Uninstalling multiprocess-0.70.9:\n",
            "      Successfully uninstalled multiprocess-0.70.9\n",
            "Successfully installed dill-0.3.2 multiprocess-0.70.10 pathos-0.2.6 pox-0.2.8 ppft-1.6.6.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.6/dist-packages (8.4.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.3.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (47.3.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting ktext\n",
            "  Downloading https://files.pythonhosted.org/packages/33/35/2e652500b5f3794749836a3ed602e3ea318d92e897fed1125c00ad7d6a45/ktext-0.40-py3-none-any.whl\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from ktext) (1.0.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from ktext) (0.14.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from ktext) (2.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ktext) (3.13)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from ktext) (8.4.0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (from ktext) (2.12.0)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from ktext) (1.0.4)\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.8MB/s \n",
            "\u001b[?25hCollecting textacy==0.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/13/77612f4393d9c8a55e53924f13b2cf8b835cbf4a5e69e288613ed2de9eca/textacy-0.6.2-py2.py3-none-any.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from ktext) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ktext) (1.18.5)\n",
            "Collecting msgpack-numpy\n",
            "  Downloading https://files.pythonhosted.org/packages/46/96/5c56e589ac85b09ca08a9799e90244f9e08602c62915cba9e2abdfce73f7/msgpack_numpy-0.4.6.post0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.6/dist-packages (from ktext) (0.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from ktext) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (1.29.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (3.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (3.2.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (2.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (2.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ktext) (1.12.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->ktext) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->ktext) (2.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktext) (1.0.8)\n",
            "Collecting pyphen>=0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/82/08a3629dce8d1f3d91db843bb36d4d7db6b6269d5067259613a0d5c8a9db/Pyphen-0.9.5-py2.py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.11.1 in /usr/local/lib/python3.6/dist-packages (from textacy==0.6.2->ktext) (4.41.1)\n",
            "Collecting ijson>=2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/82/03c325c85196744658c6d095c1e90dbd408595c596fc136b2157b2edaa10/ijson-3.0.4-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.7MB/s \n",
            "\u001b[?25hCollecting ftfy<5.0.0,>=4.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/5d/9385540977b00df1f3a0c0f07b7e6c15b5e7a3109d7f6ae78a0a764dab22/ftfy-4.4.3.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from textacy==0.6.2->ktext) (2.2.4)\n",
            "Requirement already satisfied: pyemd>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from textacy==0.6.2->ktext) (0.5.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from textacy==0.6.2->ktext) (2.23.0)\n",
            "Collecting python-levenshtein>=0.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[?25hCollecting cytoolz>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/b1/7f16703fe4a497879b1b457adf1e472fad2d4f030477698b16d2febf38bb/cytoolz-0.10.1.tar.gz (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy==0.6.2->ktext) (0.22.2.post1)\n",
            "Collecting unidecode>=0.04.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.6/dist-packages (from textacy==0.6.2->ktext) (2.4)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from textacy==0.6.2->ktext) (4.1.0)\n",
            "Requirement already satisfied: ppft>=1.6.6.2 in /usr/local/lib/python3.6/dist-packages (from pathos->ktext) (1.6.6.2)\n",
            "Requirement already satisfied: dill>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from pathos->ktext) (0.3.2)\n",
            "Requirement already satisfied: pox>=0.2.8 in /usr/local/lib/python3.6/dist-packages (from pathos->ktext) (0.2.8)\n",
            "Requirement already satisfied: multiprocess>=0.70.10 in /usr/local/lib/python3.6/dist-packages (from pathos->ktext) (0.70.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow->ktext) (47.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (1.6.0.post3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (1.17.2)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.2.0->textacy==0.6.2->ktext) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.2.0->textacy==0.6.2->ktext) (0.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (0.6.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (7.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy==0.6.2->ktext) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy==0.6.2->ktext) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy==0.6.2->ktext) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy==0.6.2->ktext) (1.24.3)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz>=0.8.0->textacy==0.6.2->ktext) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17.0->textacy==0.6.2->ktext) (0.15.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.11->textacy==0.6.2->ktext) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (1.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (4.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy<5.0.0,>=4.2.0->textacy==0.6.2->ktext) (0.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->ktext) (0.4.8)\n",
            "Building wheels for collected packages: ftfy, python-levenshtein, cytoolz\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-4.4.3-cp36-none-any.whl size=41068 sha256=b8b3cbb5cb95094e643e6bd3f36ebb9e28317646c773bf76438945bd08d35e54\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/54/00/d320239bfc8aad1455314f302dd82a75253fc585e17b81704e\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144794 sha256=8e8195869c317f1882be35802043a5d13d3a86c378fbdf4f5ce4446fae873713\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.10.1-cp36-cp36m-linux_x86_64.whl size=1233757 sha256=bd364a1d54c4068021a2bb838c0b2dae492a1446b8ca7385661ff683d1754686\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/2a/18/d962b614e055577e7d9a3e4813e0742f822ca9c8800cc3783a\n",
            "Successfully built ftfy python-levenshtein cytoolz\n",
            "Installing collected packages: keras, pyphen, ijson, ftfy, python-levenshtein, cytoolz, unidecode, textacy, msgpack-numpy, ktext\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed cytoolz-0.10.1 ftfy-4.4.3 ijson-3.0.4 keras-2.2.4 ktext-0.40 msgpack-numpy-0.4.6.post0 pyphen-0.9.5 python-levenshtein-0.12.0 textacy-0.6.2 unidecode-1.1.1\n",
            "Collecting annoy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/15/5a9db225ebda93a235aebd5e42bbf83ab7035e7e4783c6cb528c635c9afb/annoy-1.16.3.tar.gz (644kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 3.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.16.3-cp36-cp36m-linux_x86_64.whl size=297323 sha256=be8a2b219b7a7082df4c9ea8bfbbe17f3dabb49c8c1f3e20821356f143136b0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/01/54/6ef760fe9f9fc6ba8c19cebbe6358212b5f3b5b0195c0b813f\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.16.3\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.61)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.6.0+cu101)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.18.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.5.0+cu101)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (47.3.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.5.0+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.5.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->torchvision) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSLi5mEd0oR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.WARNING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgg4djW__Nqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe2b114d-8514-4b3d-8e24-df63fed352e4"
      },
      "source": [
        "from pathlib import Path\n",
        "INPUT_PATH = Path(base_dir)\n",
        "INPUT_FILE = Path(INPUT_PATH/'github_issues.csv')\n",
        "print(\"INPUT_FILE = \", INPUT_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT_FILE =  /content/gdrive/My Drive/seq2seq-model/github_issues.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdTewsxjzf0A",
        "colab_type": "text"
      },
      "source": [
        "# Process Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxfMUyISzf0F",
        "colab_type": "text"
      },
      "source": [
        "Look at filesystem to see files extracted from BigQuery (or Kaggle: https://www.kaggle.com/davidshinn/github-issues/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc8CvtRDzf0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lah | grep INPUT_FILE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SO4mXMOzf0g",
        "colab_type": "text"
      },
      "source": [
        "Split data into train and test set and preview data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwmRPpn-zf0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "113a7007-483c-43a8-cad8-22f0bf25bd65"
      },
      "source": [
        "#read in data sample 2M rows (for speed of tutorial)\n",
        "traindf, testdf = train_test_split(pd.read_csv(INPUT_FILE).sample(n=200000), \n",
        "                                   test_size=.10)\n",
        "\n",
        "\n",
        "#print out stats about shape of data\n",
        "print(f'Train: {traindf.shape[0]:,} rows {traindf.shape[1]:,} columns')\n",
        "print(f'Test: {testdf.shape[0]:,} rows {testdf.shape[1]:,} columns')\n",
        "\n",
        "# preview data\n",
        "traindf.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 180,000 rows 3 columns\n",
            "Test: 20,000 rows 3 columns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>issue_url</th>\n",
              "      <th>issue_title</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3372507</th>\n",
              "      <td>\"https://github.com/jmarceli/array2xml/issues/8\"</td>\n",
              "      <td>always use cdata for tag content</td>\n",
              "      <td>for the sake of consistency, wouldn't be better to always use cdata blocks for the tag content? in this way, the value supplied can always be used as is, and will never require any escaping even if performed automatically . also, this would get rid of the prefix. finally, when a tag has both attributes and a value, it should be possible to get rid of both ! and % prefixes by using the first value with numeric key as the value for the tag, that is, instead of 'photos' =&gt; array 'photo' =&gt; arra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855380</th>\n",
              "      <td>\"https://github.com/MoePlayer/DPlayer/issues/120\"</td>\n",
              "      <td>if i want to add svg icon , how should i do ?</td>\n",
              "      <td>if i want to add svg icon , how should i do ? / svg used by dplayer / const svgsource = { 'play': '0 0 16 32', 'm15.552 15.168q0.448 0.32 0.448 0.832 0 0.448-0.448 0.768l-13.696 8.512q-0.768 0.512-1.312 0.192t-0.544-1.28v-16.448q0-0.96 0.544-1.28t1.312 0.192z' }; how create the play svg icon data?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3157007</th>\n",
              "      <td>\"https://github.com/AndreiGubskii/html_group_8_teamwork_team_5/issues/28\"</td>\n",
              "      <td>собрать и протестировать страницу singlework</td>\n",
              "      <td>&lt;h2&gt; задача&lt;/h3&gt; - cобрать и протестировать страницу макета https://drive.google.com/drive/folders/0b_ucljvtcpnlwu1ptfitvwjrd2s . - блоки макета должны корректно отображаться - адаптивная страница - блоки не ломаются при резайзе экрана. - если найдете баг или не соответствие блоков по дизайну макета, обращайтесь в чат нашей команды. &lt;h2&gt;время&lt;/h2&gt; по плану: 2 часа по факту:</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         issue_url  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 body\n",
              "3372507                           \"https://github.com/jmarceli/array2xml/issues/8\"  ...  for the sake of consistency, wouldn't be better to always use cdata blocks for the tag content? in this way, the value supplied can always be used as is, and will never require any escaping even if performed automatically . also, this would get rid of the prefix. finally, when a tag has both attributes and a value, it should be possible to get rid of both ! and % prefixes by using the first value with numeric key as the value for the tag, that is, instead of 'photos' => array 'photo' => arra...\n",
              "855380                           \"https://github.com/MoePlayer/DPlayer/issues/120\"  ...                                                                                                                                                                                                           if i want to add svg icon , how should i do ? / svg used by dplayer / const svgsource = { 'play': '0 0 16 32', 'm15.552 15.168q0.448 0.32 0.448 0.832 0 0.448-0.448 0.768l-13.696 8.512q-0.768 0.512-1.312 0.192t-0.544-1.28v-16.448q0-0.96 0.544-1.28t1.312 0.192z' }; how create the play svg icon data?\n",
              "3157007  \"https://github.com/AndreiGubskii/html_group_8_teamwork_team_5/issues/28\"  ...                                                                                                                             <h2> задача</h3> - cобрать и протестировать страницу макета https://drive.google.com/drive/folders/0b_ucljvtcpnlwu1ptfitvwjrd2s . - блоки макета должны корректно отображаться - адаптивная страница - блоки не ломаются при резайзе экрана. - если найдете баг или не соответствие блоков по дизайну макета, обращайтесь в чат нашей команды. <h2>время</h2> по плану: 2 часа по факту:\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1de7Djizf04",
        "colab_type": "text"
      },
      "source": [
        "**Convert to lists in preparation for modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02BXpruDzf08",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "fa121a59-7608-46ea-c1d7-26304db4b3bb"
      },
      "source": [
        "train_body_raw = traindf.body.tolist()\n",
        "train_title_raw = traindf.issue_title.tolist()\n",
        "#preview output of first element\n",
        "train_body_raw[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"for the sake of consistency, wouldn't be better to always use cdata blocks for the tag content? in this way, the value supplied can always be used as is, and will never require any escaping even if performed automatically . also, this would get rid of the prefix. finally, when a tag has both attributes and a value, it should be possible to get rid of both ! and % prefixes by using the first value with numeric key as the value for the tag, that is, instead of 'photos' => array 'photo' => array 0 => array '@mainphoto' => '1', '%' => '1.png', , 1 => array '@mainphoto' => '0', '%' => '2.png', , 2 => array '@mainphoto' => '0', '%' => '3.png', it should be sufficient to write 'photos' => array 'photo' => array 0 => array '@mainphoto' => '1', '1.png', , 1 => array '@mainphoto' => '0', '2.png', , 2 => array '@mainphoto' => '0', '3.png',\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4IlN9ZLzf1R",
        "colab_type": "text"
      },
      "source": [
        "# Pre-Process Data For Deep Learning\n",
        "\n",
        "See [this repo](https://github.com/hamelsmu/ktext) for documentation on the ktext package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNR7JZwCzf1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "from ktext.preprocess import processor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWTAgZmlzf1r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "952e1fe3-5f58-4aee-c191-04de84631fa1"
      },
      "source": [
        "%%time\n",
        "# Clean, tokenize, and apply padding / truncating such that each document length = 70\n",
        "#  also, retain only the top 8,000 words in the vocabulary and set the remaining words\n",
        "#  to 1 which will become common index for rare words \n",
        "with strategy.scope(): \n",
        "  body_pp = processor(keep_n=8000, padding_maxlen=70)\n",
        "  train_body_vecs = body_pp.fit_transform(train_body_raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:....tokenizing data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9J20Vjozf11",
        "colab_type": "text"
      },
      "source": [
        "#### Look at one example of processed issue bodies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wMEpHsjzf13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "9ad23354-10b6-4203-f93c-f7659abe4546"
      },
      "source": [
        "print('\\noriginal string:\\n', train_body_raw[0], '\\n')\n",
        "print('after pre-processing:\\n', train_body_vecs[0], '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-742efeab5392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\noriginal string:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_body_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after pre-processing:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_body_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_body_raw' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldF4uws4zf2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "48b3c7fc-bb1f-4e3f-b569-4a5562bee082"
      },
      "source": [
        "# Instantiate a text processor for the titles, with some different parameters\n",
        "#  append_indicators = True appends the tokens '_start_' and '_end_' to each\n",
        "#                      document\n",
        "#  padding = 'post' means that zero padding is appended to the end of the \n",
        "#             of the document (as opposed to the default which is 'pre')\n",
        "title_pp = processor(append_indicators=True, keep_n=4500, \n",
        "                     padding_maxlen=12, padding ='post')\n",
        "\n",
        "# process the title data\n",
        "train_title_vecs = title_pp.fit_transform(train_title_raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7640dfdce735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#  padding = 'post' means that zero padding is appended to the end of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#             of the document (as opposed to the default which is 'pre')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m title_pp = processor(append_indicators=True, keep_n=4500, \n\u001b[0m\u001b[1;32m      7\u001b[0m                      padding_maxlen=12, padding ='post')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'processor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qam8ze3Uzf2O",
        "colab_type": "text"
      },
      "source": [
        "#### Look at one example of processed issue titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxy-7kuozf2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\noriginal string:\\n', train_title_raw[0])\n",
        "print('after pre-processing:\\n', train_title_vecs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbcArnsQB78-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_PATH = Path(base_dir +'./data/seq2seq/')\n",
        "OUTPUT_PATH.mkdir(exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJgFvjLyzf2e",
        "colab_type": "text"
      },
      "source": [
        "Serialize all of this to disk for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsZnf8ZRzf2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dill as dpickle\n",
        "import numpy as np\n",
        "\n",
        "# Save the preprocessor\n",
        "with open(OUTPUT_PATH/'body_pp.dpkl', 'wb') as f:\n",
        "    dpickle.dump(body_pp, f)\n",
        "\n",
        "with open(OUTPUT_PATH/'title_pp.dpkl', 'wb') as f:\n",
        "    dpickle.dump(title_pp, f)\n",
        "\n",
        "# Save the processed data\n",
        "np.save(OUTPUT_PATH/'train_title_vecs.npy', train_title_vecs)\n",
        "np.save(OUTPUT_PATH/'train_body_vecs.npy', train_body_vecs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Ot7Z_Yzf2s",
        "colab_type": "text"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL02IQM5zf2u",
        "colab_type": "text"
      },
      "source": [
        "### Load the data from disk into variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyu19SJlzf2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from seq2seq_utils import load_decoder_inputs, load_encoder_inputs, load_text_processor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msTDN8yuzf29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data, doc_length = load_encoder_inputs(OUTPUT_PATH/'train_body_vecs.npy')\n",
        "decoder_input_data, decoder_target_data = load_decoder_inputs(OUTPUT_PATH/'train_title_vecs.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LND5WoNuzf3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_encoder_tokens, body_pp = load_text_processor(OUTPUT_PATH/'body_pp.dpkl')\n",
        "num_decoder_tokens, title_pp = load_text_processor(OUTPUT_PATH/'title_pp.dpkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E45s1C-zf3Z",
        "colab_type": "text"
      },
      "source": [
        "### Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwufZr2-zf30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, BatchNormalization\n",
        "from tensorflow.keras import optimizers\n",
        "from seq2seq_utils import viz_model_architecture\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
        "with strategy.scope(): \n",
        "  #arbitrarly set latent dimension for embedding and hidden units\n",
        "  latent_dim = 300\n",
        "\n",
        "  ##### Define Model Architecture ######\n",
        "\n",
        "  ########################\n",
        "  #### Encoder Model ####\n",
        "  encoder_inputs = Input(shape=(doc_length,), name='Encoder-Input')\n",
        "\n",
        "  # Word embeding for encoder (ex: Issue Body)\n",
        "  x = Embedding(num_encoder_tokens, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
        "  x = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n",
        "\n",
        "  # Intermediate GRU layer (optional)\n",
        "  #x = GRU(latent_dim, name='Encoder-Intermediate-GRU', return_sequences=True)(x)\n",
        "  #x = BatchNormalization(name='Encoder-Batchnorm-2')(x)\n",
        "\n",
        "  # We do not need the `encoder_output` just the hidden state.\n",
        "  _, state_h = GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x)\n",
        "\n",
        "  # Encapsulate the encoder as a separate entity so we can just \n",
        "  #  encode without decoding if we want to.\n",
        "  encoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n",
        "\n",
        "  seq2seq_encoder_out = encoder_model(encoder_inputs)\n",
        "\n",
        "  ########################\n",
        "  #### Decoder Model ####\n",
        "  decoder_inputs = Input(shape=(None,), name='Decoder-Input')  # for teacher forcing\n",
        "\n",
        "  # Word Embedding For Decoder (ex: Issue Titles)\n",
        "  dec_emb = Embedding(num_decoder_tokens, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
        "  dec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
        "\n",
        "  # Set up the decoder, using `decoder_state_input` as initial state.\n",
        "  decoder_gru = GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\n",
        "  decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\n",
        "  x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
        "\n",
        "  # Dense layer for prediction\n",
        "  decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Final-Output-Dense')\n",
        "  decoder_outputs = decoder_dense(x)\n",
        "\n",
        "  ########################\n",
        "  #### Seq2Seq Model ####\n",
        "\n",
        "  #seq2seq_decoder_out = decoder_model([decoder_inputs, seq2seq_encoder_out])\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDF8mLZ6U5I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope(): \n",
        "  seq2seq_Model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  seq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')\n",
        "  seq2seq_Model.summary() \n",
        "  script_name_base = 'tutorial_seq2seq'\n",
        "  csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
        "  model_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n",
        "                                   save_best_only=True)\n",
        "\n",
        "  batch_size = 1200\n",
        "  epochs = 7\n",
        "  history = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.12, callbacks=[csv_logger, model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88p2g6UBzf3-",
        "colab_type": "text"
      },
      "source": [
        "** Examine Model Architecture Summary **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZfrKiF9zf4J",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR12Favqzf4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save model\n",
        "seq2seq_Model.save(OUTPUT_PATH/'seq2seq_model_tutorial.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ADEX-Hozf4e",
        "colab_type": "text"
      },
      "source": [
        "# See Results On Holdout Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_L60Jnzzf4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from seq2seq_utils import Seq2Seq_Inference\n",
        "seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=body_pp,\n",
        "                                 decoder_preprocessor=title_pp,\n",
        "                                 seq2seq_model=seq2seq_Model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "FVsJzITzzf4o",
        "colab_type": "code",
        "colab": {},
        "outputId": "f71bbe6a-d5eb-4910-a188-3d8fec54438d"
      },
      "source": [
        "# this method displays the predictions on random rows of the holdout set\n",
        "seq2seq_inf.demo_model_predictions(n=50, issue_df=testdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 137237 =================\n",
            "\n",
            "\"https://github.com/envisionnw/upland/issues/90\"\n",
            "Issue Body:\n",
            " <a href= https://github.com/ncpn ><img src= https://avatars3.githubusercontent.com/u/9699622?v=3 align= left width= 96 height= 96 hspace= 10 ></img></a> issue by ncpn https://github.com/ncpn _friday mar 17, 2017 at 19:31 gmt_\n",
            "_originally opened as https://github.com/ncpn/upland/issues/90_ ---- check for odd species after completing the plot. compare with list of prior year's species. paper list \n",
            "\n",
            "Original Title:\n",
            " end of plot issues - identify odd species\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " closed species plot not working\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 132413 =================\n",
            "\n",
            "\"https://github.com/open-organization-ambassadors/open-org-it-culture/issues/38\"\n",
            "Issue Body:\n",
            " need to include a specific call to the opensource.com writers list during the announcement part of the book series process. \n",
            "\n",
            "Original Title:\n",
            " update announcement process\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add a list of the book series to the book\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 110893 =================\n",
            "\n",
            "\"https://github.com/arquillian/arquillian-cube/issues/795\"\n",
            "Issue Body:\n",
            " issue overview add a new property to disable detection of image stream files those ended with -is.yml from target directory. expected behaviour by default cube should not process image stream files if user does not set it. current behaviour cube always try to execute -is.yml files which can cause some problems in most of cases, for example if you are using kuberentes instead of openshift or if you use together fabric8 maven plugin with cube. \n",
            "\n",
            "Original Title:\n",
            " add a new property to disable detection of image stream files\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add a way to disable image detection\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 179062 =================\n",
            "\n",
            "\"https://github.com/TryGhost/Ghost/issues/9299\"\n",
            "Issue Body:\n",
            " in ghost 1.0 we set out to get rid of incremental ids. we didn't quite achieve it, as the migrations table still uses it, and i believe there is still some hardcoded expectations around the ghost owner id. regarding incremental ids in the migrations table i raised an issue on knex migrator: https://github.com/tryghost/knex-migrator/issues/91 we need to also try to get rid of reliance on ids inside of ghost itself. this issue needs more detail really - raising it as a starting point. \n",
            "\n",
            "Original Title:\n",
            " remove all reliance on incremental ids\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " incremental migration to oracle db\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 54381 =================\n",
            "\n",
            "\"https://github.com/googlevr/gvr-unity-sdk/issues/509\"\n",
            "Issue Body:\n",
            " hi, i'm trying to get the deep link working. i can send the activity, open the app and read dashcode and get booleanextra and all that. so activating the deep link works fine and for example when i call getaction, it returns android.intent.action.view which is correct. the main problem is that getdatastring and getscheme always return null. i'm out of test ideas. do you think its a bug? i have attached the manifest file for your reference. and i'm using gvrintent.getdata that always returns null. islaunchedfromvr and getintenthashcode are working fine. and this is the command line i used to test as an example: ./adb shell am start -w -a android.intent.action.view -d shapevisual://com.shapevisual.app?wl=gfs com.shapevisual.app androidmanifest.xml.txt https://github.com/googlevr/gvr-unity-sdk/files/864522/androidmanifest.xml.txt \n",
            "\n",
            "Original Title:\n",
            " android - deep link - getdatastring always returns null\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " deep link and null return\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 113341 =================\n",
            "\n",
            "\"https://github.com/sten626/mirror-match/issues/26\"\n",
            "Issue Body:\n",
            " right now there is no logging of any kind. read up on proper app logging in angular and add it to the app. \n",
            "\n",
            "Original Title:\n",
            " add logging to app\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add logging to app\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 57566 =================\n",
            "\n",
            "\"https://github.com/convox/praxis/issues/319\"\n",
            "Issue Body:\n",
            " a pro user has expressed a need for this. \n",
            "\n",
            "Original Title:\n",
            " support for ev green bar ssl certs\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add a new user\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 199162 =================\n",
            "\n",
            "\"https://github.com/ChurchCRM/CRM/issues/2403\"\n",
            "Issue Body:\n",
            " im presently upgrading to 2.7.2 from 2.7.1, my automated update is not working from my site, so im just uploading the new code and replacing the .htaccess and config.php . is there any other changes that i should be aware of to make sure that the update is successfull ? \n",
            "\n",
            "Original Title:\n",
            " upgrading to 2.7.2\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " question : how to update the code ?\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 187512 =================\n",
            "\n",
            "\"https://github.com/keepassxreboot/keepassxc/issues/693\"\n",
            "Issue Body:\n",
            " i tried to enable and use yubikey on snap version but yubikey doesn't shows on the list of valid devices. i done a comparison with debian package same version 2.2.0 and works fine. so i think the problem could be related to snap access to usb devices. \n",
            "\n",
            "Original Title:\n",
            " yubikey doesn't works on snap version\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " snap version does n't work on ubuntu * number *\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 18015 =================\n",
            "\n",
            "\"https://github.com/primefaces/primeng/issues/4456\"\n",
            "Issue Body:\n",
            " hi folks, <h3 class= first >advanced</h3> <p-fileupload name= demo url= ./upload.php onupload = onuploadhandler $event multiple= multiple accept= image/ maxfilesize= 1000000 > <ng-template ptemplate type= content > <ul ngif= uploadedfiles.length > <li ngfor= let file of uploadedfiles >{{file.name}} - {{file.size}} bytes</li> </ul> </ng-template> </p-fileupload> onuploadhandler event:any { alert 'test' ; for let file of event.files { this.uploadedfiles.push file ; } } onuploadhandler function is not working. what's wrong? i am using primeng - ^5.0.0-rc.0. any idea? \n",
            "\n",
            "Original Title:\n",
            " onupload function is not working!\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " how to use this with multiple angular - cli * number *\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 153048 =================\n",
            "\n",
            "\"https://github.com/imabug/raddb/issues/212\"\n",
            "Issue Body:\n",
            " adding a new test type is broken. this error is produced when the submit button is pressed. httpexception in handler.php line 133: this action is unauthorized. \n",
            "\n",
            "Original Title:\n",
            " error adding new test type\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " new test issue\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 28004 =================\n",
            "\n",
            "\"https://github.com/Carthage/Carthage/issues/1936\"\n",
            "Issue Body:\n",
            " one of the more confusing parts around how carthage installation works currently is that it requires a dylib itself with many more embedded dylibs to be installed alongside the carthage binary carthagekit.framework . if we have support for 1379, would it be possible to statically link carthage's dependencies into the primary carthage binary? if so, it could mean that there would be only one file to install. the primary unanswered question in my mind is whether it's possible to statically link against the swift core dylibs. does anyone know if there's an exposed way to do this? they seem to be present at this path /applications/xcode.app/contents/developer/toolchains/xcodedefault.xctoolchain/usr/lib/swift_static/macosx , so perhaps it is as simple as linking against these .a files. it would be a little strange for carthage to use the non-default flow for embedding built frameworks, but it is a cli rather than an app so perhaps this may be a good choice for this scenario. additionally, this would likely resolve issues where another version of carthagekit.framework steaks into a user's @rpath before the one that they just downloaded, causing a new version of the carthage binary to use the wrong version of carthagekit.framework . thoughts? thanks for reading. \n",
            "\n",
            "Original Title:\n",
            " statically link carthage frameworks into carthage?\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add carthage support for carthage\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 131367 =================\n",
            "\n",
            "\"https://github.com/qlicker/qlicker/issues/341\"\n",
            "Issue Body:\n",
            " when looking at the course details as a professor, the message add ta to ... shows up when clicking the add student button. \n",
            "\n",
            "Original Title:\n",
            " add student to course displays the wrong message\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add ta to ta course\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 82152 =================\n",
            "\n",
            "\"https://github.com/RetroWoW/RetroWoW/issues/96\"\n",
            "Issue Body:\n",
            " description : hunter pets are not summoned upon res in battleground current behaviour : hunter pets are not summoned upon res in battleground expected behaviour : spirit guides in battlegrounds should summon/resurrect your current pet when the hunter is resurrected. steps to reproduce the problem : 1. die in a bg 2. get resurected 3. source: http://wowwiki.wikia.com/wiki/patch_1.5.0 \n",
            "\n",
            "Original Title:\n",
            " hunter pets are not summoned upon res in battleground\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " * number*.2 * number*.5 not possible to be used in a new\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 160809 =================\n",
            "\n",
            "\"https://github.com/kubernetes/ingress-nginx/issues/1825\"\n",
            "Issue Body:\n",
            " ie 11 does not support permanent redirect 308 with default headers, so it might not be the best default. it was introduced in this pull request: https://github.com/kubernetes/ingress-nginx/pull/1776 you could also support a fall back mode based on user agent: https://stackoverflow.com/questions/37701100/redirecting-ie-7-and-ie-11-by-useragent-nginx-config it might be possible to get ie 11 to support permanent redirect 308 if the redirect page presented does not trigger compatibility mode, but older versions of ie still won't support 308. \n",
            "\n",
            "Original Title:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " permanent redirect 308 not supported in ie11\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " redirect to * number * redirect does not work\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 197532 =================\n",
            "\n",
            "\"https://github.com/ngrx/platform/issues/49\"\n",
            "Issue Body:\n",
            " export const selectfeature = createfeatureselector<featurestate> 'feature' ; ~~~~~~~~~~~~~~~ error ts4023: exported variable 'selectfeature' has or is using name 'memoizedselector' from external module .../ngrx/modules/store/src/selector but cannot be named. \n",
            "\n",
            "Original Title:\n",
            " memoizedselector needs to be exported as well\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " export ' ' : ' can not be used in ' module\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 163719 =================\n",
            "\n",
            "\"https://github.com/aspnet/StaticFiles/issues/211\"\n",
            "Issue Body:\n",
            " staticfiles/src/microsoft.aspnet.staticfiles/fileextensioncontenttypeprovider.cs is missing the outlook .msg mimetype - currently manually doing the following: var provider = new fileextensioncontenttypeprovider ; provider.mappings.add .msg , application/vnd.ms-outlook ; ... but i think it would be good to have it included directly in the code. \n",
            "\n",
            "Original Title:\n",
            " missing .msg mimetype mapping\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " missing outlook / auto - parsing of the source - code\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 169328 =================\n",
            "\n",
            "\"https://github.com/epics-modules/autosave/issues/13\"\n",
            "Issue Body:\n",
            " tech talk message as follows: > hello, > > > here at slac, we saw that autosave is failing to recover the data for a waveform with 1 element. for testing purposes, we changed manually nelm to 2 and the recovery succeeded. another test was to manually edit the sav file, adding the keyword @array@ and the recovering succeeded, too.​ > > > i saw the following comment in 5.4.1 release: previously, restoring an array which had been saved with zero or one values failed. also, manual restore including restore by configmenu of any array pv caused a seg fault. . > > > as we are using 5.7.1, i think this problem is already corrected since 5.4.1. the behavior was observed when using epics 3.15. > > > the strange thing is that the same version of autosave seems to be working in epics 3.14, but not in 3.15. > > > i saw that autosave uses ca_element_count from the channel access api. maybe something changed in this function in epics 3.15? > > > thank you for your help. > > > márcio paduan donadio > > system control engineer - slac > \n",
            "\n",
            "Original Title:\n",
            " recovering data from waveform with 1 element\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " recover the data from the * number *\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 85076 =================\n",
            "\n",
            "\"https://github.com/kristoferjoseph/flexboxgrid/issues/233\"\n",
            "Issue Body:\n",
            " hello! when i using auto width: <div class= row center-xs center-sm center-md center-lg > <div class= col-xs col-sm col-md col-lg > <div class= box top bottom id= white >1</div> </div> <div class= col-xs col-sm col-md col-lg > <div class= box top bottom id= white >2</div> </div> </div> in chrome, firefox, vivaldi and android devices, all ok - content is transferred as filling: ! screenshot at 15 15-23-31 https://cloud.githubusercontent.com/assets/13396947/22974363/ff5ee854-f392-11e6-91ef-01844d8f655d.png but in safari om macos , displayed content in one row and add horizontal scroll: ! screenshot at 15 15-27-25 https://cloud.githubusercontent.com/assets/13396947/22974432/4ff8d496-f393-11e6-8abe-c04a6029d9ef.png how can i fix it? \n",
            "\n",
            "Original Title:\n",
            " content filling on safari\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " table not working\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 13218 =================\n",
            "\n",
            "\"https://github.com/koorellasuresh/UKRegionTest/issues/82803\"\n",
            "Issue Body:\n",
            " first from flow in uk south \n",
            "\n",
            "Original Title:\n",
            " first from flow in uk south\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " first from flow in uk south\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 193511 =================\n",
            "\n",
            "\"https://github.com/highcharts/highcharts/issues/7347\"\n",
            "Issue Body:\n",
            " i'm using highstockcharts and recently upgraded to v6.0.3. since then, the tooltips won't be shown anymore as soon as the tooltip is higher than the actual chart. see the minimum example which i've provided. expected behaviour the tooltip should be shown. actual behaviour the tooltip is not shown if the tooltip the height is larger than the actual chart. live demo with steps to reproduce http://jsfiddle.net/n1h3q3sr/ uncomment the part teststring += <br/> not working anymore to make the tooltip visible. affected browser s chrome / firefox and most probably ie too \n",
            "\n",
            "Original Title:\n",
            " tooltip is not shown anymore if tooltip is larger than the chart\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " tooltip not shown on * number *\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 7320 =================\n",
            "\n",
            "\"https://github.com/Criccle/GoogleCombo/issues/1\"\n",
            "Issue Body:\n",
            " unlike google chart for mendix, google combo chart for mendix cannot redraw a chart. only one chart can be drawn only once but no redraw or two charts in a page is possible. thus, this module is useless at all with this condition. \n",
            "\n",
            "Original Title:\n",
            " cannot redraw a chart by google combo chart for mendix\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " google charts not working\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 42159 =================\n",
            "\n",
            "\"https://github.com/cviebrock/eloquent-sluggable/issues/337\"\n",
            "Issue Body:\n",
            " hello! i have a model with multiple slug fields setup like this: return 'slug_en' => 'source' => 'name_en' , 'slug_es' => 'source' => 'name_es' , 'slug_fr' => 'source' => 'name_fr' , 'slug_it' => 'source' => 'name_it' , 'slug_de' => 'source' => 'name_de' , ; i want to findbyslug on all of them, i have tried with slugkeyname but no luck. is there something im missing? thank you \n",
            "\n",
            "Original Title:\n",
            " find on multiple slug fields\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " multiple fields with same name\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 184774 =================\n",
            "\n",
            "\"https://github.com/hylang/hy/issues/1271\"\n",
            "Issue Body:\n",
            " it was released in 2008, so it's almost 10 years old. also, we don't test it. \n",
            "\n",
            "Original Title:\n",
            " drop support for python 2.6\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " remove old version from * number *\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 121668 =================\n",
            "\n",
            "\"https://github.com/MajkiIT/polish-ads-filter/issues/3646\"\n",
            "Issue Body:\n",
            " @majkiit w prebake jest reguła, która psuje logowanie na gg. a najwyraźniej są jeszcze osoby, które korzystają z gg i z listy prebake. więc nie wiem czy warto dać whitelist na nasz filtr czy nie, co o tym sądzisz? https://github.com/azet12/popupblocker/issues/68 issuecomment-329763381 \n",
            "\n",
            "Original Title:\n",
            " gg.pl prebake\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " problem z login\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 34871 =================\n",
            "\n",
            "\"https://github.com/WorldDominationArmy/geodk-reqtest-req/issues/1\"\n",
            "Issue Body:\n",
            " afsnit: 3. krav til løsningens overordnede egenskaber relateret: \n",
            "\n",
            "Original Title:\n",
            " krav 1-eksterne kilder til datasupplering\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " * number * - * number * - * number * -\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 7978 =================\n",
            "\n",
            "\"https://github.com/blockstack/blockstack-portal/issues/416\"\n",
            "Issue Body:\n",
            " i noticed that gmp is installed by the macos installer script. noticed that the library was not loaded https://github.com/blockstack/blockstack-portal/issues/415 issuecomment-294392702 for albert: library not loaded: /usr/local/opt/gmp/lib/libgmp.10.dylib referenced from: /private/tmp/blockstack-venv/lib/python2.7/site-packages/fastecdsa/curvemath.so reason: image not found he is on macos 10.12. let's see if we can reproduce this error locally. \n",
            "\n",
            "Original Title:\n",
            " testing gmp and libffi installation via script\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " library not loaded in macos\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 28099 =================\n",
            "\n",
            "\"https://github.com/EcrituresNumeriques/transformation_jats_erudit/issues/2\"\n",
            "Issue Body:\n",
            " avons-nous une liste définitive des attributs possible de 'fig-type' pour l'extrant de jats? le balisage de mon côté, pour érudit, dépend de la valeur sémantique de l'attribut de cette balise et je voudrais pouvoir styler les différents cas de figures haha , qui sont : <figure>, <tableau>, <encadre>, <objetmedia>, pour les images et le son. merci. \n",
            "\n",
            "Original Title:\n",
            " attributs possibles pour <fig> sous jats\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " * number * : gestion des dates\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 24459 =================\n",
            "\n",
            "\"https://github.com/go-gitea/gitea/issues/656\"\n",
            "Issue Body:\n",
            " when adding a new member to an organisation owner team, addteammember does not set watches for the new team member. together with 653 that is pretty confusing behaviour and probably a bug. \n",
            "\n",
            "Original Title:\n",
            " new owner team member does not get watches for org repo's\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " new member does not set the team member\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 64152 =================\n",
            "\n",
            "\"https://github.com/linuxboss182/SoftEng-2017/issues/84\"\n",
            "Issue Body:\n",
            " need 3-4 people to present our application to the class on wednesday. applicants must: - not have presented last week - understand how to use the application - be ready to kick ass remember, you have to present at either this wednesday or the next one, so plan accordingly! \n",
            "\n",
            "Original Title:\n",
            " iteration 2 presentation\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add a new class to the application\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 69032 =================\n",
            "\n",
            "\"https://github.com/kartoza/qgis.org.za/issues/184\"\n",
            "Issue Body:\n",
            " i created a form 'contact' and it seems to work but the form labels do not appear on the form so it is a bit useless. please get the labels to appear and merge and release with other improvements asap \n",
            "\n",
            "Original Title:\n",
            " form labels not appearing\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " form labels not showing up\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 132252 =================\n",
            "\n",
            "\"https://github.com/NTU-ASH/tree-generator/issues/18\"\n",
            "Issue Body:\n",
            " sort a series of node values within the tree, e.g. -take values from 0-9 up to 15 -sort them into a tree with the middle value as the root and the lowest on the left/highest on the right -perhaps do the same for letters so a is to the left and z is to the right \n",
            "\n",
            "Original Title:\n",
            " binary search tree generation\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " sort tree nodes\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 53765 =================\n",
            "\n",
            "\"https://github.com/multiformats/multihash/issues/74\"\n",
            "Issue Body:\n",
            " why not use the existing crypt format? $.$ \n",
            "\n",
            "Original Title:\n",
            " why not use the existing crypt format? $.$\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " why not use the existing format ?\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 123370 =================\n",
            "\n",
            "\"https://github.com/PSEBergclubBern/BergclubBern/issues/181\"\n",
            "Issue Body:\n",
            " ich kann bilder einfügen: ! 2017-05-07 14_01_33-tourenbericht anpassen bergclub bern wordpress https://cloud.githubusercontent.com/assets/18282099/25780754/d2260da6-332d-11e7-8350-f46821b300d5.png aber auf der website werden diese nicht angezeigt: ! 2017-05-07 14_00_32-bergclub bern https://cloud.githubusercontent.com/assets/18282099/25780756/defc015c-332d-11e7-982e-e51b758c8179.png \n",
            "\n",
            "Original Title:\n",
            " bilder eines tourenberichts werden nicht angezeigt\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " website : update to * url *\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 57636 =================\n",
            "\n",
            "\"https://github.com/postmanlabs/postman-app-support/issues/2996\"\n",
            "Issue Body:\n",
            " welcome to the postman issue tracker. any feature requests / bug reports can be posted here. any security-related bugs should be reported directly to security@getpostman.com version/app information: 1. postman version: 4.10.7 2. app chrome app or mac app : linux app not sure if its also happening on other oss 3. os details: ubuntu 14.06 4. is the interceptor on and enabled in the app: no 5. did you encounter this recently, or has this bug always been there: 6. expected behaviour: explain below steps to repoduce 7. console logs http://blog.getpostman.com/2014/01/27/enabling-chrome-developer-tools-inside-postman/ for the chrome app, view->toggle dev tools for the mac app : 8. screenshots if applicable steps to reproduce the problem: it seems postman ignores the failures if there is 1<= passed test after the failed assertion. i.e: assertion a a=true assertion b=false must fails the test assertion c c=true the final outcome of the postman test must be false because b failed. but postman shows the final results as passed because it looks at c which was true as the last line of the test which is wrong and the test easily ignores any bug and marks the test as successfull. some guidelines: 1. please file newman-related issues at https://github.com/postmanlabs/newman/issues 2. if it’s a cloud-related issue, or you want to include personal information like your username / collection names, mail us at help@getpostman.com 3. if it’s a question anything along the lines of “how do i … in postman” , the answer might lie in our documentation - http://getpostman.com/docs. \n",
            "\n",
            "Original Title:\n",
            " postman is skiping the failed assestions if the last assersion passes\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " feature request : add support for multiple devices\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 120461 =================\n",
            "\n",
            "\"https://github.com/libgraviton/gdk-java/issues/23\"\n",
            "Issue Body:\n",
            " with 12 rql support was introduced for string and date fields. since the rql syntax varies depending on the field type, integer and float and boolean are currently not supported, since they get treated as regular string fields. lets have a look at a typical query against a string field _fieldname_ with the value _value_ ?eq fieldname,string:value in this case the string: prefix is not required. it has the same result as ?eq fieldname,value but lets look at another example again a string field ?eq fieldname,string:20 at this point the string: prefix is required, since the graviton rql parser needs to know it's dealing with a string. omitting string: would lead to an empty result on the other hand, if we look at an integer field ?eq integerfieldname,string:20 would lead to an empty result. in this case the query needs to look like ?eq integerfieldname,string:20 the part that needs changing is https://github.com/libgraviton/gdk-java/blob/develop/gdk-core/src/main/java/com/github/libgraviton/gdk/api/query/rql/rql.java l141 where currently every field is always treated as string. \n",
            "\n",
            "Original Title:\n",
            " integer, float and boolean support for rql\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " support for numeric type\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 3333 =================\n",
            "\n",
            "\"https://github.com/jpvillaisaza/hangman/issues/15\"\n",
            "Issue Body:\n",
            " losing a game and then restarting shouldn't count as two more games. just one, thanks. \n",
            "\n",
            "Original Title:\n",
            " fix total number of games\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " game crashes when game is running\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 133450 =================\n",
            "\n",
            "\"https://github.com/vector-im/riot-meta/issues/28\"\n",
            "Issue Body:\n",
            " placeholder overarching issue to track progress on: general ux polish should probably be decomposed further. \n",
            "\n",
            "Original Title:\n",
            " general ux polish\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add more info to the ui\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 111482 =================\n",
            "\n",
            "\"https://github.com/Viva-con-Agua/drops/issues/21\"\n",
            "Issue Body:\n",
            " currently, the view for defining the roles is very confusing. a search field for searching users has to be implemented and the role selection should be a little bit more user friendly. \n",
            "\n",
            "Original Title:\n",
            " roles definition view\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " improve search for user roles\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 154925 =================\n",
            "\n",
            "\"https://github.com/srusskih/SublimeJEDI/issues/228\"\n",
            "Issue Body:\n",
            " i want edit my project config file. according to the readme , by default project config name is <project name>.sublime-project , so the project is the folder that holds the project py file? \n",
            "\n",
            "Original Title:\n",
            " how to define a project ?\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " how to edit project name ?\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 18851 =================\n",
            "\n",
            "\"https://github.com/climategadgets/servomaster/issues/7\"\n",
            "Issue Body:\n",
            " adafruit dc & stepper motor hat for raspberry pi - mini kit https://www.adafruit.com/product/2348 provides a very reproducible and standard stepper controller solution for raspberry pi, it would be a shame not to support it. this enhancement is much more complicated than 6, though. steppers, unlike servos, do not have inherent limits, and if a stepper is used as a servo, there will have to be solutions put in place to allow limit detection limit switches and torque sensors, to name a couple . in addition, stepper positioning model discrete steps is different from servo positioning model floating point 0 to 1 with adjustable ranges and limits , so some extra work will need to be done. \n",
            "\n",
            "Original Title:\n",
            " implement tb6612 driver for raspberry pi\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " rpi motor support\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 174664 =================\n",
            "\n",
            "\"https://github.com/cawilliamson/ansible-gpdpocket/issues/98\"\n",
            "Issue Body:\n",
            " first off, thanks for all the effort going into this, very promising. issue: trying to bootstrap an ubuntu-16.04.3 iso from within an existing ubuntu instance. running into an error, which appears to be when ansible starts getting involved. very possible i'm doing something wrong. e: can not write log is /dev/pts mounted? - posix_openpt 2: no such file or directory + grep -wq -- --nogit + echo 'skip pulling source from git' + cd /usr/src/ansible-gpdpocket + ansible_nocows=1 + ansible-playbook system.yml -e bootstrap=true -v warning : provided hosts list is empty, only localhost is available error! syntax error while loading yaml. the error appears to have been in '/usr/src/ansible-gpdpocket/roles/audio/tasks/main.yml': line 17, column 1, but may be elsewhere in the file depending on the exact syntax problem. the offending line appears to be: - name: create chtrt5645 directory ^ here play recap localhost : ok=23 changed=14 unreachable=0 failed=1 \n",
            "\n",
            "Original Title:\n",
            " syntax error while loading yaml\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " bootstrap fails to mount in ubuntu\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 186883 =================\n",
            "\n",
            "\"https://github.com/prettydiff/prettydiff/issues/456\"\n",
            "Issue Body:\n",
            " right now a single language file handles all tasks for a given group of languages. these files need to be broken down into respective pieces: parser beautifier minifier analyzer this is a large architectural effort. fortunately the code is well segmented internally for separation of concerns, so the logic can be broken apart without impact to operational integrity. the challenge is largely administration to ensure all the pieces are included into each of the respective environments and pass data among each other appropriately. \n",
            "\n",
            "Original Title:\n",
            " separate language files into their respective tasks\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " fix language handling for all languages\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 151593 =================\n",
            "\n",
            "\"https://github.com/koorellasuresh/UKRegionTest/issues/21568\"\n",
            "Issue Body:\n",
            " first from flow in uk south \n",
            "\n",
            "Original Title:\n",
            " first from flow in uk south\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " first from flow in uk south\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 24718 =================\n",
            "\n",
            "\"https://github.com/sensorario/go-tris/issues/34\"\n",
            "Issue Body:\n",
            " move 1 simone : 5 move 2 computer : 2 move 3 simone : 9 move 4 computer : 1 move 5 simone : 3 move 6 computer : 6 move 7 simone : 8 move 8 computer : 7 move 9 simone : 4 \n",
            "\n",
            "Original Title:\n",
            " in this case computer loose\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " move to * number *\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 2005 =================\n",
            "\n",
            "\"https://github.com/fossasia/susi_firefoxbot/issues/6\"\n",
            "Issue Body:\n",
            " actual behaviour only text response from the server is shown expected behaviour support different types of responses like images, links, tables etc. would you like to work on the issue ? yes \n",
            "\n",
            "Original Title:\n",
            " support for different types of responses from server\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " support for different types of response\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 144769 =================\n",
            "\n",
            "\"https://github.com/reallyenglish/ansible-role-poudriere/issues/8\"\n",
            "Issue Body:\n",
            " the role clones a remote git repository, which takes time to clone. to make the test faster, create a small, but functional repository in the role, and use it for the test. \n",
            "\n",
            "Original Title:\n",
            " create minimal ports tree for the test\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add a test to the repo\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 148842 =================\n",
            "\n",
            "\"https://github.com/felquis/HTJSON/issues/2\"\n",
            "Issue Body:\n",
            " firstly - thanks for making this, i had the same idea. but i would do it slightly differently. exactly 2 differerences. 1. i'd make content an array 2. i'd more the objects inside attr down a level and get rid of it. thus content would be an attribute. for example, instead of : var template = { a : { attr : { href : http://your-domain.com/images/any-image.jpg }, content: { link name } } }; it'd be: var template = a : { href : http://your-domain.com/images/any-image.jpg , content : some text , { img : { src: http://whatever.jpg }, some more text } ; 1. makes it more compact, without losing any document structure information 2. makes it more versatile, and, in fact, makes it complete - it can then encode any html document. \n",
            "\n",
            "Original Title:\n",
            " shouldn't content be an array? is attr really neccessary?\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " content - type : attribute\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 83915 =================\n",
            "\n",
            "\"https://github.com/rrdelaney/ava-rethinkdb/issues/3\"\n",
            "Issue Body:\n",
            " when i run the ava-rethinkdb it works but when i ran it through travis ci i get error: spawn rethinkdb enoent is there something i am doing wrong or need to add for ci build? \n",
            "\n",
            "Original Title:\n",
            " error: spawn rethinkdb enoent\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " spawn enoent on ci\n",
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 22941 =================\n",
            "\n",
            "\"https://github.com/cartalyst/stripe/issues/90\"\n",
            "Issue Body:\n",
            " i am using your latest release 2.0.9 but that release does not include the payout file. kidnly upload the latest release that has the payout work. \n",
            "\n",
            "Original Title:\n",
            " payout file is missing in latest release.\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " release * number*.1 missing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FXEdqdvzf4x",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45YfioPzzf4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read All 5M data points\n",
        "all_data_df = pd.read_csv('github_issues.csv')\n",
        "# Extract the bodies from this dataframe\n",
        "all_data_bodies = all_data_df['body'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po-Ms-uZzf4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform all of the data using the ktext processor\n",
        "all_data_vectorized = body_pp.transform_parallel(all_data_bodies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-0DR1Uczf5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save transformed data\n",
        "with open('all_data_vectorized.dpkl', 'wb') as f:\n",
        "    dpickle.dump(all_data_vectorized, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ilHxGezzf5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "from seq2seq_utils import Seq2Seq_Inference\n",
        "seq2seq_inf_rec = Seq2Seq_Inference(encoder_preprocessor=body_pp,\n",
        "                                    decoder_preprocessor=title_pp,\n",
        "                                    seq2seq_model=seq2seq_Model)\n",
        "recsys_annoyobj = seq2seq_inf_rec.prepare_recommender(all_data_vectorized, all_data_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "G_GVQqxkzf5Y",
        "colab_type": "text"
      },
      "source": [
        "### Example 1: Issues Installing Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJS9FWYvzf5Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "33023992-5e79-49e4-91c0-30495a287b75"
      },
      "source": [
        "seq2seq_inf_rec.demo_model_predictions(n=1, issue_df=testdf, threshold=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 13563 =================\n",
            "\n",
            "\"https://github.com/bnosac/pattern.nlp/issues/5\"\n",
            "Issue Body:\n",
            " thanks for your package, i can't wait to use it. unfortunately i have issues with the installation. prerequisite is 'first install python version 2.5+ not version 3 '. so this package cant be used with version 3.6 64bit that i have installed? i nevertheless tried to install it using pip, conda is not supported? but got an error: 'syntaxerror: missing parentheses in call to 'print''. besides when i try to run the library in r version 3.3.3. 64 bit i got errors with can_find_python_cmd required_modules = pattern.db : 'error in find_python_cmd......' pattern seems to be written in python but must be used in r, why cant it be used in python? i found another python pattern application that apparently does the same in python: https://pypi.python.org/pypi/pattern how is this related? \n",
            "\n",
            "Original Title:\n",
            " error installation python\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " install with python * number *\n",
            "\n",
            "**** Similar Issues (using encoder embedding) ****:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>issue_url</th>\n",
              "      <th>issue_title</th>\n",
              "      <th>body</th>\n",
              "      <th>dist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>286906</th>\n",
              "      <td>\"https://github.com/scikit-hep/root_numpy/issues/337\"</td>\n",
              "      <td>root 6.10/02 and root_numpy compatibility</td>\n",
              "      <td>i am trying to pip install root_pandas and one of the dependency is root_numpy however some weird reasons i am unable to install it even though i can import root in python. i am working on python3.6 as i am more comfortable with it. is root_numpy is not yet compatible with the latest root?</td>\n",
              "      <td>0.694671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314005</th>\n",
              "      <td>\"https://github.com/andim/noisyopt/issues/4\"</td>\n",
              "      <td>joss review: installing dependencies via pip</td>\n",
              "      <td>hi, i'm trying to install noisyopt in a clean conda environment running python 3.5. running pip install noisyopt does not install the dependencies numpy, scipy . i see that you do include a requires keyword argument in your setup.py file, does this need to be install_requires ? as in https://packaging.python.org/requirements/ . also, not necessary if you don't want to, but i think it would be good to include a list of dependences somewhere in the readme.</td>\n",
              "      <td>0.698265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48120</th>\n",
              "      <td>\"https://github.com/turi-code/SFrame/issues/389\"</td>\n",
              "      <td>python 3.6 compatible</td>\n",
              "      <td>hi: i tried to install sframe using pip and conda but i can not find anything that will work with python 3.6? has sframe been updated to work with python 3.6 yet? thanks, drew</td>\n",
              "      <td>0.718715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    issue_url  \\\n",
              "286906  \"https://github.com/scikit-hep/root_numpy/issues/337\"   \n",
              "314005           \"https://github.com/andim/noisyopt/issues/4\"   \n",
              "48120        \"https://github.com/turi-code/SFrame/issues/389\"   \n",
              "\n",
              "                                         issue_title  \\\n",
              "286906     root 6.10/02 and root_numpy compatibility   \n",
              "314005  joss review: installing dependencies via pip   \n",
              "48120                          python 3.6 compatible   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                              body  \\\n",
              "286906                                                                                                                                                                          i am trying to pip install root_pandas and one of the dependency is root_numpy however some weird reasons i am unable to install it even though i can import root in python. i am working on python3.6 as i am more comfortable with it. is root_numpy is not yet compatible with the latest root?   \n",
              "314005  hi, i'm trying to install noisyopt in a clean conda environment running python 3.5. running pip install noisyopt does not install the dependencies numpy, scipy . i see that you do include a requires keyword argument in your setup.py file, does this need to be install_requires ? as in https://packaging.python.org/requirements/ . also, not necessary if you don't want to, but i think it would be good to include a list of dependences somewhere in the readme.   \n",
              "48120                                                                                                                                                                                                                                                                                              hi: i tried to install sframe using pip and conda but i can not find anything that will work with python 3.6? has sframe been updated to work with python 3.6 yet? thanks, drew   \n",
              "\n",
              "            dist  \n",
              "286906  0.694671  \n",
              "314005  0.698265  \n",
              "48120   0.718715  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqNyBuBpzf5g",
        "colab_type": "text"
      },
      "source": [
        "### Example 2:  Issues asking for feature improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa5_nwm3zf5h",
        "colab_type": "code",
        "colab": {},
        "outputId": "2d251bf5-03cb-4193-cc06-9fd16908fd9c"
      },
      "source": [
        "seq2seq_inf_rec.demo_model_predictions(n=1, issue_df=testdf, threshold=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "==============================================\n",
            "============== Example # 157322 =================\n",
            "\n",
            "\"https://github.com/Chingu-cohorts/devgaido/issues/89\"\n",
            "Issue Body:\n",
            " right now, your profile link is https://devgaido.com/profile. this is fine, but it would be really cool if there was a way to share your profile with other people. on my portfolio, i have social media buttons to freecodecamp, github, ect. without a custom link, i cannot show-off what i have done on devgaido to future employers. \n",
            "\n",
            "Original Title:\n",
            " feature request: sharable profile.\n",
            "\n",
            "****** Machine Generated Title (Prediction) ******:\n",
            " add a link to your profile\n",
            "\n",
            "**** Similar Issues (using encoder embedding) ****:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>issue_url</th>\n",
              "      <th>issue_title</th>\n",
              "      <th>body</th>\n",
              "      <th>dist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>250423</th>\n",
              "      <td>\"https://github.com/ParabolInc/action/issues/1379\"</td>\n",
              "      <td>integrations list view discoverability</td>\n",
              "      <td>issue - enhancement i was initially confused by the link to my account copy; seeing github in the integrations list made me think it had already been set up . i realize now that i had to allow parabol to post as me. i think that link to my account could use a tooltip explaining what link means, and why you'd want to do so. &lt;img width= 728 alt= screen shot 2017-09-29 at 10 52 05 am src= https://user-images.githubusercontent.com/2146312/31024786-2fd39c46-a50e-11e7-9f2a-6d4a5ed2baeb.png &gt;</td>\n",
              "      <td>0.748828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222304</th>\n",
              "      <td>\"https://github.com/viosey/hexo-theme-material/issues/166\"</td>\n",
              "      <td>allow us to use sns-share for github</td>\n",
              "      <td>i'd love to be able to add a link at the bottom of the page for my github account. however, the sns-share option doesn't currently seem to be able to do this.</td>\n",
              "      <td>0.774398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153327</th>\n",
              "      <td>\"https://github.com/tobykurien/GoogleApps/issues/31\"</td>\n",
              "      <td>drive provide download ability</td>\n",
              "      <td>sometimes people share files via g drive. provided a link this app can show some info about the files but doesn't show the download button. i hope that it can be fixed and users would be able to download files with this app.</td>\n",
              "      <td>0.778953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         issue_url  \\\n",
              "250423          \"https://github.com/ParabolInc/action/issues/1379\"   \n",
              "222304  \"https://github.com/viosey/hexo-theme-material/issues/166\"   \n",
              "153327        \"https://github.com/tobykurien/GoogleApps/issues/31\"   \n",
              "\n",
              "                                   issue_title  \\\n",
              "250423  integrations list view discoverability   \n",
              "222304    allow us to use sns-share for github   \n",
              "153327          drive provide download ability   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              body  \\\n",
              "250423  issue - enhancement i was initially confused by the link to my account copy; seeing github in the integrations list made me think it had already been set up . i realize now that i had to allow parabol to post as me. i think that link to my account could use a tooltip explaining what link means, and why you'd want to do so. <img width= 728 alt= screen shot 2017-09-29 at 10 52 05 am src= https://user-images.githubusercontent.com/2146312/31024786-2fd39c46-a50e-11e7-9f2a-6d4a5ed2baeb.png >   \n",
              "222304                                                                                                                                                                                                                                                                                                                                              i'd love to be able to add a link at the bottom of the page for my github account. however, the sns-share option doesn't currently seem to be able to do this.   \n",
              "153327                                                                                                                                                                                                                                                                            sometimes people share files via g drive. provided a link this app can show some info about the files but doesn't show the download button. i hope that it can be fixed and users would be able to download files with this app.   \n",
              "\n",
              "            dist  \n",
              "250423  0.748828  \n",
              "222304  0.774398  \n",
              "153327  0.778953  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxGtR_Izzf5q",
        "colab_type": "code",
        "colab": {},
        "outputId": "d0d2fdfb-af53-417c-bbd5-de66a7bf3a40"
      },
      "source": [
        "# incase you need to reset the rec system\n",
        "# seq2seq_inf_rec.set_recsys_annoyobj(recsys_annoyobj)\n",
        "# seq2seq_inf_rec.set_recsys_data(all_data_df)\n",
        "\n",
        "# save object\n",
        "recsys_annoyobj.save('recsys_annoyobj.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfZbr440zf54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}